# LLM API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

GOOGLE_API_KEY=your_google_api_key_here
COHERE_API_KEY=your_cohere_api_key_here

# Custom model configuration
# For any model not directly supported by our providers
CUSTOM_MODEL=your_custom_model_name
CUSTOM_BASE_URL=https://your-api-endpoint/v1
CUSTOM_API_KEY=your_custom_api_key
# API Type can be: openai_compatible or raw_completion
CUSTOM_API_TYPE=openai_compatible

# Base URL for the OpenAI instance (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
# OpenRouter: https://openrouter.ai/api/v1
# Anthropic: https://api.anthropic.com/v1
BASE_URL=

# Generic LLM API Key - used as a fallback or with BASE_URL
# For OpenAI: https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# For Anthropic: https://console.anthropic.com/account/keys
# For OpenRouter: https://openrouter.ai/keys
# For Ollama, no need to set this unless you specifically configured an API key
LLM_API_KEY=

# Database connections
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_key_here

# For the Supabase version, set your Supabase URL and Service Key.
# Get your SUPABASE_URL from the API section of your Supabase project settings
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_SERVICE_KEY=

# Pinecone vector database settings
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp

# Model selection
# The LLM you want to use for the reasoner (o3-mini, R1, QwQ, etc.).
# Example: o3-mini
# Example: deepseek-r1:7b-8k
REASONER_MODEL=

# The LLM you want to use for the primary agent/coder.
# Example: gpt-4o-mini
# Example: qwen2.5:14b-instruct-8k
PRIMARY_MODEL=

# Embedding model you want to use
# Example for Ollama: nomic-embed-text
# Example for OpenAI: text-embedding-3-small
EMBEDDING_MODEL=text-embedding-ada-002

# Logging
LOG_LEVEL=INFO
